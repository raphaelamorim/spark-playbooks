{
  "post_stream": {
    "posts": [
      {
        "id": 1702245,
        "name": "Alan Dang",
        "username": "alan.dang",
        "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
        "created_at": "2025-10-26T18:28:22.282Z",
        "cooked": "<p>I’m trying to convert nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-FP8 into a TRTLLM Engine.</p>\n<p>I pull the 1.10rc3 container optimized for the spark. and it starts to load weights.  It gets to</p>\n<p><code>[TensorRT-LLM] TensorRT-LLM version: 1.1.0rc3</code><br>\n<code>[TensorRT-LLM][INFO] Refreshed the MPI local session</code><br>\n<code>You are using a model of type nemotron-nas to instantiate a model of type nemotron_nas. This is not supported for all configurations of models and can yield errors.</code><br>\n<code>Loading safetensors weights in parallel: 100%|██████████| 11/11 [00:00&lt;00:00, 42.53it/s]</code><br>\n<code>Loading weights concurrently: 100%|██████████| 1219/1219 [03:20&lt;00:00,  6.07it/s]</code><br>\n<code>Model init total – 216.25s</code><br>\n<code>[TensorRT-LLM][INFO] Number of tokens per block: 32.</code><br>\n<code>[TensorRT-LLM][INFO] [MemUsageChange] Allocated 0.77 GiB for max tokens in paged KV cache (8256).</code><br>\n<code>2025-10-26 18:21:43,982 - INFO - flashinfer.jit: Loading JIT ops: norm</code><br>\n<code>2025-10-26 18:21:57,794 - INFO - flashinfer.jit: Finished loading JIT ops: norm</code><br>\n<code>[TensorRT-LLM][WARNING] Attention workspace size is not enough, increase the size from 0 bytes to 100732416 bytes</code><br>\n<code>[TensorRT-LLM][WARNING] CheckTactic failed with status: 8 and heuristic status: 8 with workspace size: 28.</code></p>\n<p>(That checktactic error goes on repeatedly.)</p>\n<p>Am I just running out of memory because that’s too large of a model to build an engine on GB10?  Or is there a problem with my code and I just need to keep debugging?</p>\n<p>Thanks.  (And does it matter that 1.1.0rc3 runs CUDA 12.9 even though it’s the DGX Spark container<br>\n<code>nvcr.io/nvidia/tensorrt-llm/release:spark-single-gpu-dev</code></p>",
        "post_number": 1,
        "post_type": 1,
        "posts_count": 5,
        "updated_at": "2025-10-26T18:28:22.282Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 74,
        "reads": 39,
        "readers_count": 38,
        "score": 322.8,
        "yours": false,
        "topic_id": 348981,
        "topic_slug": "maximum-model-size-to-build-trt-llm-engine-on-dgx-spark",
        "display_username": "Alan Dang",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 835463,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/maximum-model-size-to-build-trt-llm-engine-on-dgx-spark/348981/1",
        "event": null,
        "calendar_details": [],
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_vote": false,
        "can_translate": false
      },
      {
        "id": 1703203,
        "name": "Aniculescu",
        "username": "aniculescu",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/aniculescu/{size}/382649_2.png",
        "created_at": "2025-10-27T21:06:40.673Z",
        "cooked": "<p>The DGX Spark supports AI models up to 200 billion parameters, so a 49B model should not be the issue here unless you are using system memory to run other workloads at the same time</p>",
        "post_number": 2,
        "post_type": 1,
        "posts_count": 5,
        "updated_at": "2025-10-27T21:06:40.673Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 25,
        "readers_count": 24,
        "score": 5.0,
        "yours": false,
        "topic_id": 348981,
        "topic_slug": "maximum-model-size-to-build-trt-llm-engine-on-dgx-spark",
        "display_username": "Aniculescu",
        "primary_group_name": "Employee",
        "flair_name": "Employee",
        "flair_url": null,
        "flair_bg_color": "",
        "flair_color": "",
        "flair_group_id": 63,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": "Moderator",
        "title_is_group": false,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": true,
        "admin": false,
        "staff": true,
        "user_id": 3567453,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/maximum-model-size-to-build-trt-llm-engine-on-dgx-spark/348981/2",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1703222,
        "name": "Alan Dang",
        "username": "alan.dang",
        "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
        "created_at": "2025-10-27T22:29:47.533Z",
        "cooked": "<p>Thanks. My understanding is that while I am able to deploy the model using GGUFs easily (where the 200B NVFP4 metric comes from), if I am building a TRT-LLM engine, my understanding is that it can require <em>much</em> more VRAM than the model itself?  So even though Nemotron 49B v1.5 is 53GB in Q8, it needs more than 128GB unified RAM to build a NVFP4 or Q8 engine?</p>\n<p>Nemotron Nano 9B v2 works, but I just want to know if NVIDIA has some guidelines for TRT-LLM engine building on DGX Spark in terms of model size that leaves enough overhead.</p>",
        "post_number": 3,
        "post_type": 1,
        "posts_count": 5,
        "updated_at": "2025-10-27T22:29:47.533Z",
        "reply_count": 1,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 3,
        "reads": 22,
        "readers_count": 21,
        "score": 24.4,
        "yours": false,
        "topic_id": 348981,
        "topic_slug": "maximum-model-size-to-build-trt-llm-engine-on-dgx-spark",
        "display_username": "Alan Dang",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 835463,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/maximum-model-size-to-build-trt-llm-engine-on-dgx-spark/348981/3",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1703283,
        "name": "Aniculescu",
        "username": "aniculescu",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/aniculescu/{size}/382649_2.png",
        "created_at": "2025-10-27T23:49:26.603Z",
        "cooked": "<p>I did not see that you wanted to build a trt-llm engine. It is very possible you do not have enough memory to build an engine, I’m not sure on the memory requirements for that process.<br>\nHowever, you can use the TensorRT optimizer to create a NVFP4 quantized version of the model and deploy it with TRT-LLM. You can find an example in our playbooks: <a href=\"https://build.nvidia.com/spark/nvfp4-quantization/overview\" class=\"inline-onebox\">Try NVIDIA NIM APIs</a></p>",
        "post_number": 4,
        "post_type": 1,
        "posts_count": 5,
        "updated_at": "2025-10-27T23:49:26.603Z",
        "reply_count": 0,
        "reply_to_post_number": 3,
        "quote_count": 0,
        "incoming_link_count": 4,
        "reads": 21,
        "readers_count": 20,
        "score": 24.2,
        "yours": false,
        "topic_id": 348981,
        "topic_slug": "maximum-model-size-to-build-trt-llm-engine-on-dgx-spark",
        "display_username": "Aniculescu",
        "primary_group_name": "Employee",
        "flair_name": "Employee",
        "flair_url": null,
        "flair_bg_color": "",
        "flair_color": "",
        "flair_group_id": 63,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://build.nvidia.com/spark/nvfp4-quantization/overview",
            "internal": false,
            "reflection": false,
            "title": "Try NVIDIA NIM APIs",
            "clicks": 15
          }
        ],
        "read": true,
        "user_title": "Moderator",
        "title_is_group": false,
        "reply_to_user": {
          "id": 835463,
          "username": "alan.dang",
          "name": "Alan Dang",
          "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": true,
        "admin": false,
        "staff": true,
        "user_id": 3567453,
        "hidden": false,
        "trust_level": 2,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/maximum-model-size-to-build-trt-llm-engine-on-dgx-spark/348981/4",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": true,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1715795,
        "name": "system",
        "username": "system",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/system/{size}/68080_2.png",
        "created_at": "2025-11-17T19:31:07.122Z",
        "cooked": "<p>This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</p>",
        "post_number": 5,
        "post_type": 3,
        "posts_count": 5,
        "updated_at": "2025-11-17T19:31:07.122Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 1,
        "readers_count": 0,
        "score": 0.2,
        "yours": false,
        "topic_id": 348981,
        "topic_slug": "maximum-model-size-to-build-trt-llm-engine-on-dgx-spark",
        "display_username": "system",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": "Moderator",
        "title_is_group": false,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": true,
        "admin": true,
        "staff": true,
        "user_id": -1,
        "hidden": false,
        "trust_level": 4,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "action_code": "autoclosed.enabled",
        "post_url": "/t/maximum-model-size-to-build-trt-llm-engine-on-dgx-spark/348981/5",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      }
    ],
    "stream": [
      1702245,
      1703203,
      1703222,
      1703283,
      1715795
    ]
  },
  "timeline_lookup": [
    [
      1,
      30
    ],
    [
      2,
      29
    ],
    [
      5,
      8
    ]
  ],
  "suggested_topics": [],
  "tags": [
    "llama",
    "nemotron"
  ],
  "tags_descriptions": {},
  "fancy_title": "Maximum model size to build TRT-LLM Engine on DGX Spark?",
  "id": 348981,
  "title": "Maximum model size to build TRT-LLM Engine on DGX Spark?",
  "posts_count": 5,
  "created_at": "2025-10-26T18:28:22.194Z",
  "views": 164,
  "reply_count": 1,
  "like_count": 0,
  "last_posted_at": "2025-10-27T23:49:26.603Z",
  "visible": true,
  "closed": true,
  "archived": false,
  "has_summary": false,
  "archetype": "regular",
  "slug": "maximum-model-size-to-build-trt-llm-engine-on-dgx-spark",
  "category_id": 721,
  "word_count": 489,
  "deleted_at": null,
  "user_id": 835463,
  "featured_link": null,
  "pinned_globally": false,
  "pinned_at": null,
  "pinned_until": null,
  "image_url": null,
  "slow_mode_seconds": 0,
  "draft": null,
  "draft_key": "topic_348981",
  "draft_sequence": null,
  "unpinned": null,
  "pinned": false,
  "current_post_number": 1,
  "highest_post_number": 5,
  "deleted_by": null,
  "actions_summary": [
    {
      "id": 4,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 8,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 10,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 7,
      "count": 0,
      "hidden": false,
      "can_act": false
    }
  ],
  "chunk_size": 20,
  "bookmarked": false,
  "topic_timer": null,
  "message_bus_last_id": 0,
  "participant_count": 2,
  "show_read_indicator": false,
  "thumbnails": null,
  "slow_mode_enabled_until": null,
  "related_topics": [
    {
      "fancy_title": " could not find any implementation for node 2-layer MLP, try increasing the workspace size with IBuilder::setMaxWorkspaceSize()",
      "id": 66503,
      "title": " could not find any implementation for node 2-layer MLP, try increasing the workspace size with IBuilder::setMaxWorkspaceSize()",
      "slug": "could-not-find-any-implementation-for-node-2-layer-mlp-try-increasing-the-workspace-size-with-ibuilder-setmaxworkspacesize",
      "posts_count": 5,
      "reply_count": 0,
      "highest_post_number": 5,
      "image_url": null,
      "created_at": "2018-10-23T02:39:25.000Z",
      "last_posted_at": "2021-10-12T19:48:12.394Z",
      "bumped": true,
      "bumped_at": "2018-11-16T07:22:38.000Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 3790,
      "category_id": 92,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 196350,
            "username": "shmlearning",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster, Accepted Answer",
          "user": {
            "id": 192972,
            "username": "NVES",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/nves/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 194387,
            "username": "AndrewGong",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 194229,
            "username": "TomNVIDIA",
            "name": "TomNVIDIA",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/tomnvidia/{size}/14181_2.png",
            "primary_group_name": "NsightGraphicsPro",
            "flair_name": "Administrator",
            "flair_url": "https://global.discourse-cdn.com/nvidia/original/3X/7/8/786c2b0600281de14dd72c7e2d4b32c9acf7e1de.png",
            "flair_group_id": 56,
            "admin": true,
            "moderator": true,
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "when i Creating a Lite Engine From a TensorFlow Model, there occurs an error, what does it mean",
      "id": 55141,
      "title": "when i Creating a Lite Engine From a TensorFlow Model, there occurs an error, what does it mean",
      "slug": "when-i-creating-a-lite-engine-from-a-tensorflow-model-there-occurs-an-error-what-does-it-mean",
      "posts_count": 5,
      "reply_count": 0,
      "highest_post_number": 5,
      "image_url": null,
      "created_at": "2017-11-13T09:23:06.000Z",
      "last_posted_at": "2021-10-18T18:27:25.388Z",
      "bumped": true,
      "bumped_at": "2017-11-16T05:17:52.000Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 826,
      "category_id": 81,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 55880,
            "username": "742824147",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster, Accepted Answer",
          "user": {
            "id": 34659,
            "username": "AastaLLL",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/aastalll/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 6598,
            "username": "nadeemm",
            "name": "",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/nadeemm/{size}/367020_2.png",
            "primary_group_name": "Employee",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "[TensorRT] ERROR: Internal error: could not find any implementation for node (Unnamed Layer* 25) [Deconvolution], try increasing the workspace size with IBuilder::setMaxWorkspaceSize()",
      "id": 69318,
      "title": "[TensorRT] ERROR: Internal error: could not find any implementation for node (Unnamed Layer* 25) [Deconvolution], try increasing the workspace size with IBuilder::setMaxWorkspaceSize()",
      "slug": "tensorrt-error-internal-error-could-not-find-any-implementation-for-node-unnamed-layer-25-deconvolution-try-increasing-the-workspace-size-with-ibuilder-setmaxworkspacesize",
      "posts_count": 3,
      "reply_count": 0,
      "highest_post_number": 3,
      "image_url": null,
      "created_at": "2019-01-11T18:32:01.000Z",
      "last_posted_at": "2021-10-12T19:48:11.955Z",
      "bumped": true,
      "bumped_at": "2019-01-11T18:52:34.000Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 4583,
      "category_id": 92,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster, Accepted Answer",
          "user": {
            "id": 186728,
            "username": "m.abi888131",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 194229,
            "username": "TomNVIDIA",
            "name": "TomNVIDIA",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/tomnvidia/{size}/14181_2.png",
            "primary_group_name": "NsightGraphicsPro",
            "flair_name": "Administrator",
            "flair_url": "https://global.discourse-cdn.com/nvidia/original/3X/7/8/786c2b0600281de14dd72c7e2d4b32c9acf7e1de.png",
            "flair_group_id": 56,
            "admin": true,
            "moderator": true,
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "Run out of memory when creating TensorRT engine from onnx model",
      "id": 128260,
      "title": "Run out of memory when creating TensorRT engine from onnx model",
      "slug": "run-out-of-memory-when-creating-tensorrt-engine-from-onnx-model",
      "posts_count": 8,
      "reply_count": 4,
      "highest_post_number": 11,
      "image_url": null,
      "created_at": "2020-06-17T14:43:15.095Z",
      "last_posted_at": "2021-10-18T18:43:47.548Z",
      "bumped": true,
      "bumped_at": "2020-07-07T08:55:22.127Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [
        "tensorrt"
      ],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 2898,
      "category_id": 258,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 358514,
            "username": "lvkaleo",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster, Accepted Answer",
          "user": {
            "id": 34659,
            "username": "AastaLLL",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/aastalll/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 363784,
            "username": "AakankshaS",
            "name": "Aakankshas",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/aakankshas/{size}/14047_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 6598,
            "username": "nadeemm",
            "name": "",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/nadeemm/{size}/367020_2.png",
            "primary_group_name": "Employee",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "Myelin memory budget exceeded while building TensorRT engine with batch &gt; 1",
      "id": 160496,
      "title": "Myelin memory budget exceeded while building TensorRT engine with batch > 1",
      "slug": "myelin-memory-budget-exceeded-while-building-tensorrt-engine-with-batch-1",
      "posts_count": 5,
      "reply_count": 1,
      "highest_post_number": 6,
      "image_url": null,
      "created_at": "2020-11-26T11:45:59.334Z",
      "last_posted_at": "2021-10-12T19:47:34.397Z",
      "bumped": true,
      "bumped_at": "2020-11-29T18:32:37.883Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [
        "tensorrt"
      ],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 1001,
      "category_id": 92,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 260462,
            "username": "saifullah3396",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/saifullah3396/{size}/25160_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster, Accepted Answer",
          "user": {
            "id": 363784,
            "username": "AakankshaS",
            "name": "Aakankshas",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/aakankshas/{size}/14047_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 194229,
            "username": "TomNVIDIA",
            "name": "TomNVIDIA",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/tomnvidia/{size}/14181_2.png",
            "primary_group_name": "NsightGraphicsPro",
            "flair_name": "Administrator",
            "flair_url": "https://global.discourse-cdn.com/nvidia/original/3X/7/8/786c2b0600281de14dd72c7e2d4b32c9acf7e1de.png",
            "flair_group_id": 56,
            "admin": true,
            "moderator": true,
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "Why dla need so much workspace size?",
      "id": 172704,
      "title": "Why dla need so much workspace size?",
      "slug": "why-dla-need-so-much-workspace-size",
      "posts_count": 3,
      "reply_count": 0,
      "highest_post_number": 3,
      "image_url": null,
      "created_at": "2021-03-18T09:54:16.376Z",
      "last_posted_at": "2021-03-19T06:43:18.594Z",
      "bumped": true,
      "bumped_at": "2021-03-19T06:43:18.594Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [
        "tensorrt",
        "jetson-inference"
      ],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 836,
      "category_id": 92,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 878334,
            "username": "fanyj233",
            "name": "Fanyj233",
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 192972,
            "username": "NVES",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/nves/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 662358,
            "username": "spolisetty",
            "name": "Spolisetty",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/spolisetty/{size}/14047_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "Tensorrt Engine use too much memory",
      "id": 197746,
      "title": "Tensorrt Engine use too much memory",
      "slug": "tensorrt-engine-use-too-much-memory",
      "posts_count": 2,
      "reply_count": 0,
      "highest_post_number": 2,
      "image_url": null,
      "created_at": "2021-12-11T09:45:07.123Z",
      "last_posted_at": "2021-12-13T12:32:32.258Z",
      "bumped": true,
      "bumped_at": "2021-12-13T12:32:32.258Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [
        "tensorrt"
      ],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 1651,
      "category_id": 92,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 940828,
            "username": "Robert_Hoang",
            "name": "TienDuc_Robert_Hoang",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/robert_hoang/{size}/128746_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 192972,
            "username": "NVES",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/nves/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "PyTorch model converting to TensorRT issue  ",
      "id": 82624,
      "title": "PyTorch model converting to TensorRT issue  ",
      "slug": "pytorch-model-converting-to-tensorrt-issue",
      "posts_count": 5,
      "reply_count": 0,
      "highest_post_number": 5,
      "image_url": null,
      "created_at": "2019-10-01T18:32:26.000Z",
      "last_posted_at": "2021-10-18T18:34:08.841Z",
      "bumped": true,
      "bumped_at": "2019-10-02T09:26:01.000Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 1130,
      "category_id": 81,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster, Accepted Answer",
          "user": {
            "id": 277471,
            "username": "shcherbak.yuliya",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 34659,
            "username": "AastaLLL",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/aastalll/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 6598,
            "username": "nadeemm",
            "name": "",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/nadeemm/{size}/367020_2.png",
            "primary_group_name": "Employee",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "In creating  tensorRT engine   fc1/BiasAdd: kernel weights has count 102760448 but 134217728 was expected",
      "id": 58742,
      "title": "In creating  tensorRT engine   fc1/BiasAdd: kernel weights has count 102760448 but 134217728 was expected",
      "slug": "in-creating-tensorrt-engine-fc1-biasadd-kernel-weights-has-count-102760448-but-134217728-was-expected",
      "posts_count": 7,
      "reply_count": 0,
      "highest_post_number": 7,
      "image_url": "https://global.discourse-cdn.com/nvidia/original/3X/e/e/eebcec46334431a3e901d521b06d84671890bdd6.jpeg",
      "created_at": "2018-03-02T19:31:43.000Z",
      "last_posted_at": "2021-10-18T18:28:45.493Z",
      "bumped": true,
      "bumped_at": "2018-04-13T07:41:06.000Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": [
        {
          "max_width": null,
          "max_height": null,
          "width": 970,
          "height": 506,
          "url": "https://global.discourse-cdn.com/nvidia/original/3X/e/e/eebcec46334431a3e901d521b06d84671890bdd6.jpeg"
        },
        {
          "max_width": 800,
          "max_height": 800,
          "width": 800,
          "height": 417,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/3X/e/e/eebcec46334431a3e901d521b06d84671890bdd6_2_800x417.jpeg"
        },
        {
          "max_width": 600,
          "max_height": 600,
          "width": 600,
          "height": 312,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/3X/e/e/eebcec46334431a3e901d521b06d84671890bdd6_2_600x312.jpeg"
        },
        {
          "max_width": 400,
          "max_height": 400,
          "width": 400,
          "height": 208,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/3X/e/e/eebcec46334431a3e901d521b06d84671890bdd6_2_400x208.jpeg"
        },
        {
          "max_width": 300,
          "max_height": 300,
          "width": 300,
          "height": 156,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/3X/e/e/eebcec46334431a3e901d521b06d84671890bdd6_2_300x156.jpeg"
        },
        {
          "max_width": 200,
          "max_height": 200,
          "width": 200,
          "height": 104,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/3X/e/e/eebcec46334431a3e901d521b06d84671890bdd6_2_200x104.jpeg"
        }
      ],
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 1417,
      "category_id": 81,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 60022,
            "username": "ehabo333",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster, Accepted Answer",
          "user": {
            "id": 34659,
            "username": "AastaLLL",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/aastalll/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 6598,
            "username": "nadeemm",
            "name": "",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/nadeemm/{size}/367020_2.png",
            "primary_group_name": "Employee",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "Workspace size for Jetson Nano",
      "id": 157209,
      "title": "Workspace size for Jetson Nano",
      "slug": "workspace-size-for-jetson-nano",
      "posts_count": 5,
      "reply_count": 1,
      "highest_post_number": 7,
      "image_url": null,
      "created_at": "2020-10-16T07:38:54.031Z",
      "last_posted_at": "2021-10-18T17:40:20.881Z",
      "bumped": true,
      "bumped_at": "2020-10-19T03:36:30.416Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [
        "tensorrt",
        "jetson-inference"
      ],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 1483,
      "category_id": 76,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 329665,
            "username": "darshancganji12",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster, Accepted Answer",
          "user": {
            "id": 34659,
            "username": "AastaLLL",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/aastalll/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 6598,
            "username": "nadeemm",
            "name": "",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/nadeemm/{size}/367020_2.png",
            "primary_group_name": "Employee",
            "trust_level": 2
          }
        }
      ]
    }
  ],
  "summarizable": false,
  "accepted_answer": {
    "post_number": 4,
    "username": "aniculescu",
    "name": null,
    "excerpt": "I did not see that you wanted to build a trt-llm engine. It is very possible you do not have enough memory to build an engine, I’m not sure on the memory requirements for that process. \nHowever, you can use the TensorRT optimizer to create a NVFP4 quantized version of the model and deploy it with TR&hellip;",
    "accepter_name": null,
    "accepter_username": "aniculescu"
  },
  "can_vote": false,
  "vote_count": 0,
  "user_voted": false,
  "discourse_zendesk_plugin_zendesk_id": null,
  "discourse_zendesk_plugin_zendesk_url": "https://your-url.zendesk.com/agent/tickets/",
  "details": {
    "can_edit": false,
    "notification_level": 1,
    "participants": [
      {
        "id": 3567453,
        "username": "aniculescu",
        "name": "Aniculescu",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/aniculescu/{size}/382649_2.png",
        "post_count": 2,
        "primary_group_name": "Employee",
        "flair_name": "Employee",
        "flair_url": null,
        "flair_color": "",
        "flair_bg_color": "",
        "flair_group_id": 63,
        "moderator": true,
        "trust_level": 2
      },
      {
        "id": 835463,
        "username": "alan.dang",
        "name": "Alan Dang",
        "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
        "post_count": 2,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 1
      }
    ],
    "created_by": {
      "id": 835463,
      "username": "alan.dang",
      "name": "Alan Dang",
      "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png"
    },
    "last_poster": {
      "id": 3567453,
      "username": "aniculescu",
      "name": "Aniculescu",
      "avatar_template": "/user_avatar/forums.developer.nvidia.com/aniculescu/{size}/382649_2.png"
    },
    "links": [
      {
        "url": "https://build.nvidia.com/spark/nvfp4-quantization/overview",
        "title": "Try NVIDIA NIM APIs",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 15,
        "user_id": 3567453,
        "domain": "build.nvidia.com",
        "root_domain": "nvidia.com"
      }
    ]
  },
  "bookmarks": []
}