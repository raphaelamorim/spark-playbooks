{
  "post_stream": {
    "posts": [
      {
        "id": 1699678,
        "name": "Lakamsani",
        "username": "lakamsani",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/lakamsani/{size}/446446_2.png",
        "created_at": "2025-10-21T17:09:06.568Z",
        "cooked": "<p>Tried this morning.</p>\n<p>Failed at these two (<a href=\"https://github.com/karpathy/nanochat/blob/master/pyproject.toml#L47\" rel=\"noopener nofollow ugc\">github link</a>) during <code>uv sync</code> . Commented them out as I thought the DGX should have them already?</p>\n<pre><code class=\"lang-auto\"># target torch to cuda 12.8\n[tool.uv.sources]\ntorch = [\n    { index = \"pytorch-cu128\" },\n]\n\n[[tool.uv.index]]\nname = \"pytorch-cu128\"\nurl = \"https://download.pytorch.org/whl/cu128\"\nexplicit = true\n</code></pre>\n<p>Then it wasn‚Äôt able to find <a href=\"https://github.com/karpathy/nanochat/blob/master/speedrun.sh#L95\" rel=\"noopener nofollow ugc\">torchrun here</a> . Worked around that by installing it using info <a href=\"https://pytorch.org/get-started/locally/\" rel=\"noopener nofollow ugc\">from the docs</a> :</p>\n<p><code>pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu130</code></p>\n<p>After that it is stuck on the initial pretraining step <a href=\"https://torchrun%20--standalone%20--nproc_per_node=8%20-m%20scripts.base_train%20--%20--depth=20%20--run=$WANDB_RUN\" rel=\"noopener nofollow ugc\">here</a> as it is not able to use the GPU on DGX spark, so using CPU.</p>\n<aside class=\"onebox twitterstatus\" data-onebox-src=\"https://x.com/NVIDIAAIDev/status/1980412464949821570\">\n  <header class=\"source\">\n\n      <a href=\"https://x.com/NVIDIAAIDev/status/1980412464949821570\" target=\"_blank\" rel=\"noopener nofollow ugc\">x.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img class=\"thumbnail onebox-avatar\" alt=\"\" src=\"https://global.discourse-cdn.com/nvidia/original/4X/6/a/a/6aa45e968c148ebf5be875a945990e30ac1a79e6.jpeg\" data-dominant-color=\"8BC228\" width=\"48\" height=\"48\">\n<h4><a href=\"https://x.com/NVIDIAAIDev/status/1980412464949821570\" target=\"_blank\" rel=\"noopener nofollow ugc\">NVIDIA AI Developer</a></h4>\n<div class=\"twitter-screen-name\"><a href=\"https://x.com/NVIDIAAIDev/status/1980412464949821570\" target=\"_blank\" rel=\"noopener nofollow ugc\">@NVIDIAAIDev</a></div>\n\n<div class=\"tweet\">\n  <span class=\"tweet-description\">While at <a href=\"https://twitter.com/search?q=%23OpenSourceAIWeek\" target=\"_blank\" rel=\"noopener nofollow ugc\">#OpenSourceAIWeek</a>, <a href=\"https://twitter.com/Karpathy\" target=\"_blank\" rel=\"noopener nofollow ugc\">@Karpathy</a> received one of our first NVIDIA DGX Sparks, personally delivered by <a href=\"https://twitter.com/NaderLikeLadder\" target=\"_blank\" rel=\"noopener nofollow ugc\">@NaderLikeLadder</a> and <a href=\"https://twitter.com/Baxate_carter\" target=\"_blank\" rel=\"noopener nofollow ugc\">@Baxate_carter</a>.  \n\nüôå Excellent work by Andrej on introducing Nanochat -- an <a href=\"https://twitter.com/search?q=%23opensource\" target=\"_blank\" rel=\"noopener nofollow ugc\">#opensource</a> project that makes it easy for developers to explore and train <a target=\"_blank\" href=\"https://x.com/NVIDIAAIDev/status/1980412464949821570/video/1\" rel=\"noopener nofollow ugc\">pic.x.com/9bOXSK5YCd</a><div class=\"tweet-images\">\n  <div class=\"aspect-image-full-size\" style=\"--aspect-ratio:1920/1080;\">\n    <a href=\"https://video.twimg.com/amplify_video/1980393868454461440/vid/avc1/480x270/CUsZKBrPflnF-bAI.mp4?tag=14\" class=\"blocked-hotlinked-placeholder\" title=\"Media hosted on another site. Click to open in a new tab.\" rel=\"noopener nofollow ugc\"><svg class=\"fa d-icon d-icon-link svg-icon\" aria-hidden=\"true\"><use href=\"#link\"></use></svg><span class=\"notice\">External Media</span></a>\n  </div>\n</div></span>\n</div>\n\n<div class=\"date\">\n  <a href=\"https://x.com/NVIDIAAIDev/status/1980412464949821570\" class=\"timestamp\" target=\"_blank\" rel=\"noopener nofollow ugc\">11:15 PM - 20 Oct 2025</a>\n\n    <span class=\"like\">\n      <svg viewBox=\"0 0 512 512\" width=\"14px\" height=\"16px\" aria-hidden=\"true\"><path d=\"M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z\"></path></svg>\n      400\n    </span>\n\n    <span class=\"retweet\">\n      <svg viewBox=\"0 0 640 512\" width=\"14px\" height=\"16px\" aria-hidden=\"true\"><path d=\"M629.657 343.598L528.971 444.284c-9.373 9.372-24.568 9.372-33.941 0L394.343 343.598c-9.373-9.373-9.373-24.569 0-33.941l10.823-10.823c9.562-9.562 25.133-9.34 34.419.492L480 342.118V160H292.451a24.005 24.005 0 0 1-16.971-7.029l-16-16C244.361 121.851 255.069 96 276.451 96H520c13.255 0 24 10.745 24 24v222.118l40.416-42.792c9.285-9.831 24.856-10.054 34.419-.492l10.823 10.823c9.372 9.372 9.372 24.569-.001 33.941zm-265.138 15.431A23.999 23.999 0 0 0 347.548 352H160V169.881l40.416 42.792c9.286 9.831 24.856 10.054 34.419.491l10.822-10.822c9.373-9.373 9.373-24.569 0-33.941L144.971 67.716c-9.373-9.373-24.569-9.373-33.941 0L10.343 168.402c-9.373 9.373-9.373 24.569 0 33.941l10.822 10.822c9.562 9.562 25.133 9.34 34.419-.491L96 169.881V392c0 13.255 10.745 24 24 24h243.549c21.382 0 32.09-25.851 16.971-40.971l-16.001-16z\"></path></svg>\n      28\n    </span>\n</div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<aside class=\"onebox githubrepo\" data-onebox-src=\"https://github.com/karpathy/nanochat\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/karpathy/nanochat\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"github-row\" data-github-private-repo=\"false\">\n  <img width=\"690\" height=\"344\" class=\"thumbnail\" src=\"https://global.discourse-cdn.com/nvidia/optimized/4X/3/8/f/38f799df0c8634bb41e86b5209160a780f575852_2_690x344.png\" data-dominant-color=\"EAEBEC\">\n\n  <h3><a href=\"https://github.com/karpathy/nanochat\" target=\"_blank\" rel=\"noopener nofollow ugc\">GitHub - karpathy/nanochat: The best ChatGPT that $100 can buy.</a></h3>\n\n    <p><span class=\"github-repo-description\">The best ChatGPT that $100 can buy.</span></p>\n</div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
        "post_number": 1,
        "post_type": 1,
        "posts_count": 11,
        "updated_at": "2025-10-22T02:52:03.381Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 343,
        "reads": 76,
        "readers_count": 75,
        "score": 1629.8,
        "yours": false,
        "topic_id": 348537,
        "topic_slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
        "display_username": "Lakamsani",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 2,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://github.com/karpathy/nanochat",
            "internal": false,
            "reflection": false,
            "title": "GitHub - karpathy/nanochat: The best ChatGPT that $100 can buy.",
            "clicks": 5
          },
          {
            "url": "https://github.com/karpathy/nanochat/blob/master/pyproject.toml#L47",
            "internal": false,
            "reflection": false,
            "title": "nanochat/pyproject.toml at master ¬∑ karpathy/nanochat ¬∑ GitHub",
            "clicks": 3
          },
          {
            "url": "https://github.com/karpathy/nanochat/blob/master/speedrun.sh#L95",
            "internal": false,
            "reflection": false,
            "title": "nanochat/speedrun.sh at master ¬∑ karpathy/nanochat ¬∑ GitHub",
            "clicks": 1
          },
          {
            "url": "https://x.com/NVIDIAAIDev/status/1980412464949821570",
            "internal": false,
            "reflection": false,
            "clicks": 1
          },
          {
            "url": "https://pytorch.org/get-started/locally/",
            "internal": false,
            "reflection": false,
            "clicks": 0
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [
          {
            "id": 2,
            "count": 1
          }
        ],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 4700641,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/anyone-got-nanochat-training-working-on-the-dgx-spark/348537/1",
        "event": null,
        "calendar_details": [],
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_vote": false,
        "can_translate": false
      },
      {
        "id": 1699700,
        "name": "Lakamsani",
        "username": "lakamsani",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/lakamsani/{size}/446446_2.png",
        "created_at": "2025-10-21T18:03:18.460Z",
        "cooked": "<p>==== here is the current error ===<br>\nFile ‚Äú/home/vamsee/nanochat/scripts/base_train.py‚Äù, line 60, in<br>\nassert torch.cuda.is_available(), \"CUDA is needed for a distributed run atm\"assert torch.cuda.is_available(), ‚ÄúCUDA is needed for a distributed run atm‚Äù</p>\n<p>made some progress by re-enabling/re-installing cuda 12.8 as it should work under cuda 13 on the DGX. Then it failed like this when running with one GPU (as the  DGX Spark ) has just one) <code>torchrun --standalone --nproc_per_node=1 -m scripts.base_train ‚Äì --depth=20 --run=‚Äútesting‚Äù</code></p>\n<blockquote>\n<p>The training run failed due to a CUDA compatibility issue. The error indicates:</p>\n<p>Problem: Your GPU (NVIDIA GB10 with CUDA capability 12.1) is not fully supported by this version of PyTorch, which only supports CUDA capabilities 8.0-12.0. This causes<br>\nthe Triton compiler to fail when trying to compile kernels for sm_121a architecture.</p>\n<p>Key error:<br>\nptxas fatal   : Value ‚Äòsm_121a‚Äô is not defined for option ‚Äògpu-name‚Äô</p>\n</blockquote>\n<p>Worked around that by commenting out the <code>torch.compile</code> <a href=\"https://github.com/karpathy/nanochat/blob/master/scripts/base_train.py#L112\" rel=\"noopener nofollow ugc\">line here</a> . Seems to be running now, shows GPU being used at 96%. Lets see how this step goes‚Ä¶</p>",
        "post_number": 2,
        "post_type": 1,
        "posts_count": 11,
        "updated_at": "2025-10-22T02:56:19.714Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 4,
        "reads": 62,
        "readers_count": 61,
        "score": 32.2,
        "yours": false,
        "topic_id": 348537,
        "topic_slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
        "display_username": "Lakamsani",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 2,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://github.com/karpathy/nanochat/blob/master/scripts/base_train.py#L112",
            "internal": false,
            "reflection": false,
            "title": "nanochat/scripts/base_train.py at master ¬∑ karpathy/nanochat ¬∑ GitHub",
            "clicks": 7
          }
        ],
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 4700641,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/anyone-got-nanochat-training-working-on-the-dgx-spark/348537/2",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1700862,
        "name": "Michaeljamesott",
        "username": "michaeljamesott",
        "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
        "created_at": "2025-10-22T20:13:50.681Z",
        "cooked": "<p>Thank you for sharing. My DGX Spark is in the mail and I‚Äôm going to attempt this when it gets here.</p>",
        "post_number": 4,
        "post_type": 1,
        "posts_count": 11,
        "updated_at": "2025-10-22T20:13:50.681Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 1,
        "reads": 55,
        "readers_count": 54,
        "score": 15.8,
        "yours": false,
        "topic_id": 348537,
        "topic_slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
        "display_username": "Michaeljamesott",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 4707569,
        "hidden": false,
        "trust_level": 0,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/anyone-got-nanochat-training-working-on-the-dgx-spark/348537/4",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1700885,
        "name": "Lakamsani",
        "username": "lakamsani",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/lakamsani/{size}/446446_2.png",
        "created_at": "2025-10-22T21:12:28.024Z",
        "cooked": "<p>It crashed after 20 minutes ‚òπÔ∏è</p>\n<p>Here are the run logs and screenshots from run data saved to wandb.ai . There was a disk and memory usage spike just before the crash. Maybe it was trying to write a checkpoint to the disk? On the terminal is just said ‚Äúcrashed‚Äù .</p>\n<p>______</p>\n<p>2025-10-22 03:04:59 Vocab size: 65,536</p>\n<p>2025-10-22 03:04:59 num_layers: 20</p>\n<p>2025-10-22 03:04:59 model_dim: 1280</p>\n<p>2025-10-22 03:04:59 num_heads: 10</p>\n<p>2025-10-22 03:04:59 num_kv_heads: 10</p>\n<p>2025-10-22 03:04:59 Tokens / micro-batch / rank: 32 x 2048 = 65,536</p>\n<p>2025-10-22 03:04:59 Tokens / micro-batch: 65,536</p>\n<p>2025-10-22 03:04:59 Total batch size 524,288 =&gt; gradient accumulation steps: 8</p>\n<p>2025-10-22 03:04:59 Number of parameters: 560,988,160</p>\n<p>2025-10-22 03:04:59 Estimated FLOPs per token: 3.491758e+09</p>\n<p>2025-10-22 03:04:59 Calculated number of iterations from target data:param ratio: 21,400</p>\n<p>2025-10-22 03:04:59 Total number of training tokens: 11,219,763,200</p>\n<p>2025-10-22 03:04:59 Tokens : Params ratio: 20.00</p>\n<p>2025-10-22 03:04:59 Total training FLOPs estimate: 3.917670e+19</p>\n<p>2025-10-22 03:04:59 Scaling the LR for the AdamW parameters ‚àù1/‚àö(1280/768) = 0.774597</p>\n<p>2025-10-22 03:04:59 Muon: Grouping 80 params of shape torch.Size([1280, 1280]), device cuda:0, dtype torch.float32</p>\n<p>2025-10-22 03:04:59 Muon: Grouping 20 params of shape torch.Size([1280, 5120]), device cuda:0, dtype torch.float32</p>\n<p>2025-10-22 03:04:59 Muon: Grouping 20 params of shape torch.Size([5120, 1280]), device cuda:0, dtype torch.float32</p>\n<p>2025-10-22 03:25:31 Step 00000 | Validation bpb: 3.3015</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/nvidia/original/4X/5/3/d/53de8268ba0e0fc1239c6467e580fc164e1094ef.jpeg\" data-download-href=\"/uploads/short-url/bXWlXMem4WgNZY1PPJlylJA9zAj.jpeg?dl=1\" title=\"Screenshot_20251022_140717_Chrome\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/nvidia/optimized/4X/5/3/d/53de8268ba0e0fc1239c6467e580fc164e1094ef_2_629x500.jpeg\" alt=\"Screenshot_20251022_140717_Chrome\" data-base62-sha1=\"bXWlXMem4WgNZY1PPJlylJA9zAj\" width=\"629\" height=\"500\" srcset=\"https://global.discourse-cdn.com/nvidia/optimized/4X/5/3/d/53de8268ba0e0fc1239c6467e580fc164e1094ef_2_629x500.jpeg, https://global.discourse-cdn.com/nvidia/optimized/4X/5/3/d/53de8268ba0e0fc1239c6467e580fc164e1094ef_2_943x750.jpeg 1.5x, https://global.discourse-cdn.com/nvidia/optimized/4X/5/3/d/53de8268ba0e0fc1239c6467e580fc164e1094ef_2_1258x1000.jpeg 2x\" data-dominant-color=\"FCFCFD\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot_20251022_140717_Chrome</span><span class=\"informations\">1920√ó1524 52.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/nvidia/original/4X/a/5/1/a5106828adf860edaa51500a06f80a12309f5c66.jpeg\" data-download-href=\"/uploads/short-url/nydVUZQrR6vcWKJVA976vmilX02.jpeg?dl=1\" title=\"Screenshot_20251022_140449_Chrome\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/nvidia/optimized/4X/a/5/1/a5106828adf860edaa51500a06f80a12309f5c66_2_661x500.jpeg\" alt=\"Screenshot_20251022_140449_Chrome\" data-base62-sha1=\"nydVUZQrR6vcWKJVA976vmilX02\" width=\"661\" height=\"500\" srcset=\"https://global.discourse-cdn.com/nvidia/optimized/4X/a/5/1/a5106828adf860edaa51500a06f80a12309f5c66_2_661x500.jpeg, https://global.discourse-cdn.com/nvidia/optimized/4X/a/5/1/a5106828adf860edaa51500a06f80a12309f5c66_2_991x750.jpeg 1.5x, https://global.discourse-cdn.com/nvidia/optimized/4X/a/5/1/a5106828adf860edaa51500a06f80a12309f5c66_2_1322x1000.jpeg 2x\" data-dominant-color=\"FBFBFC\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot_20251022_140449_Chrome</span><span class=\"informations\">1920√ó1451 55.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/nvidia/original/4X/4/a/5/4a5de823e3474bbb451a8aedb4e589b49746a697.jpeg\" data-download-href=\"/uploads/short-url/aBSwGykv9zGaG9qZOkUCQJrmK23.jpeg?dl=1\" title=\"Screenshot_20251022_140648_Chrome\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/nvidia/optimized/4X/4/a/5/4a5de823e3474bbb451a8aedb4e589b49746a697_2_565x500.jpeg\" alt=\"Screenshot_20251022_140648_Chrome\" data-base62-sha1=\"aBSwGykv9zGaG9qZOkUCQJrmK23\" width=\"565\" height=\"500\" srcset=\"https://global.discourse-cdn.com/nvidia/optimized/4X/4/a/5/4a5de823e3474bbb451a8aedb4e589b49746a697_2_565x500.jpeg, https://global.discourse-cdn.com/nvidia/optimized/4X/4/a/5/4a5de823e3474bbb451a8aedb4e589b49746a697_2_847x750.jpeg 1.5x, https://global.discourse-cdn.com/nvidia/original/4X/4/a/5/4a5de823e3474bbb451a8aedb4e589b49746a697.jpeg 2x\" data-dominant-color=\"FAFAFB\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot_20251022_140648_Chrome</span><span class=\"informations\">1079√ó954 76.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/nvidia/original/4X/b/9/b/b9b44143aa8c9c3088eb1265e8799e38bcdcbd5f.jpeg\" data-download-href=\"/uploads/short-url/quOwDHJWi7XpDm4a8AZBiDijNoz.jpeg?dl=1\" title=\"Screenshot_20251022_140640_Chrome\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/nvidia/optimized/4X/b/9/b/b9b44143aa8c9c3088eb1265e8799e38bcdcbd5f_2_637x500.jpeg\" alt=\"Screenshot_20251022_140640_Chrome\" data-base62-sha1=\"quOwDHJWi7XpDm4a8AZBiDijNoz\" width=\"637\" height=\"500\" srcset=\"https://global.discourse-cdn.com/nvidia/optimized/4X/b/9/b/b9b44143aa8c9c3088eb1265e8799e38bcdcbd5f_2_637x500.jpeg, https://global.discourse-cdn.com/nvidia/optimized/4X/b/9/b/b9b44143aa8c9c3088eb1265e8799e38bcdcbd5f_2_955x750.jpeg 1.5x, https://global.discourse-cdn.com/nvidia/optimized/4X/b/9/b/b9b44143aa8c9c3088eb1265e8799e38bcdcbd5f_2_1274x1000.jpeg 2x\" data-dominant-color=\"FBFBFB\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot_20251022_140640_Chrome</span><span class=\"informations\">1920√ó1507 69.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>",
        "post_number": 5,
        "post_type": 1,
        "posts_count": 11,
        "updated_at": "2025-10-22T21:12:28.024Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 8,
        "reads": 55,
        "readers_count": 54,
        "score": 45.8,
        "yours": false,
        "topic_id": 348537,
        "topic_slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
        "display_username": "Lakamsani",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 4700641,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/anyone-got-nanochat-training-working-on-the-dgx-spark/348537/5",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1700898,
        "name": "Tim",
        "username": "dengtianshuo",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/dengtianshuo/{size}/447149_2.png",
        "created_at": "2025-10-22T21:49:09.653Z",
        "cooked": "<p>Have you tried running it from a container? As mentioned in the discussion here: <a href=\"https://github.com/karpathy/nanochat/discussions/28#discussioncomment-14735913\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Anyone managed to run training on an NVIDIA Spark yet? ¬∑ karpathy/nanochat ¬∑ Discussion #28 ¬∑ GitHub</a></p>",
        "post_number": 6,
        "post_type": 1,
        "posts_count": 11,
        "updated_at": "2025-10-22T21:49:09.653Z",
        "reply_count": 1,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 2,
        "reads": 51,
        "readers_count": 50,
        "score": 35.0,
        "yours": false,
        "topic_id": 348537,
        "topic_slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
        "display_username": "Tim",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://github.com/karpathy/nanochat/discussions/28#discussioncomment-14735913",
            "internal": false,
            "reflection": false,
            "title": "Anyone managed to run training on an NVIDIA Spark yet? ¬∑ karpathy/nanochat ¬∑ Discussion #28 ¬∑ GitHub",
            "clicks": 18
          }
        ],
        "read": true,
        "user_title": "",
        "bookmarked": false,
        "actions_summary": [
          {
            "id": 2,
            "count": 1
          }
        ],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 65802,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/anyone-got-nanochat-training-working-on-the-dgx-spark/348537/6",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1700936,
        "name": "Lakamsani",
        "username": "lakamsani",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/lakamsani/{size}/446446_2.png",
        "created_at": "2025-10-22T23:21:03.718Z",
        "cooked": "<p>Thank you for that pointer. I noticed that thread devolved into all other non DGX spark ways like using the RTX graphics cards. But will try and pull in the DGX spark specific tips there and will try on mine.</p>",
        "post_number": 7,
        "post_type": 1,
        "posts_count": 11,
        "updated_at": "2025-10-22T23:22:51.267Z",
        "reply_count": 0,
        "reply_to_post_number": 6,
        "quote_count": 0,
        "incoming_link_count": 7,
        "reads": 55,
        "readers_count": 54,
        "score": 45.8,
        "yours": false,
        "topic_id": 348537,
        "topic_slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
        "display_username": "Lakamsani",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 2,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 65802,
          "username": "dengtianshuo",
          "name": "Tim",
          "avatar_template": "/user_avatar/forums.developer.nvidia.com/dengtianshuo/{size}/447149_2.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 4700641,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/anyone-got-nanochat-training-working-on-the-dgx-spark/348537/7",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1700960,
        "name": "Alexander Falk",
        "username": "afalk42",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/afalk42/{size}/447160_2.png",
        "created_at": "2025-10-23T00:44:57.675Z",
        "cooked": "<p>I have managed to get it running on my DGX Spark just now, but it took a couple of hours of trial and error, going through documentation and forums, and consulting with GPT-5 to figure out all the steps necessary‚Ä¶</p>\n<p>This is the approach that worked for me:</p>\n<h2><a name=\"p-1700960-clone-repo-and-make-modifications-1\" class=\"anchor\" href=\"#p-1700960-clone-repo-and-make-modifications-1\"></a>Clone repo and make modifications</h2>\n<p>Get the repo and change into the project directory:</p>\n<pre><code class=\"lang-auto\">git clone https://github.com/karpathy/nanochat.git\ncd nanochat\n</code></pre>\n<h2><a name=\"p-1700960-update-requirements-and-switch-to-cuda-130-2\" class=\"anchor\" href=\"#p-1700960-update-requirements-and-switch-to-cuda-130-2\"></a>Update requirements and switch to CUDA 13.0</h2>\n<p>I found it necessary to increase the dependency requirements for torch to 2.9.0 and for triton to 3.5.0 and to switch from CUDA 12.8 to 13.0. To do that, you need to change <code>pyproject.toml</code> as follows:</p>\n<pre data-code-wrap=\"toml\"><code class=\"lang-toml\">[project]\nname = \"nanochat\"\nversion = \"0.1.0\"\ndescription = \"the minimal full-stack ChatGPT clone\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.10\"\ndependencies = [\n    \"datasets&gt;=4.0.0\",\n    \"fastapi&gt;=0.117.1\",\n    \"files-to-prompt&gt;=0.6\",\n    \"numpy==1.26.4\",\n    \"psutil&gt;=7.1.0\",\n    \"regex&gt;=2025.9.1\",\n    \"setuptools&gt;=80.9.0\",\n    \"tiktoken&gt;=0.11.0\",\n    \"tokenizers&gt;=0.22.0\",\n    \"torch&gt;=2.9.0\",\n    \"triton&gt;=3.5.0\",\n    \"uvicorn&gt;=0.36.0\",\n    \"wandb&gt;=0.21.3\",\n]\n\n[build-system]\nrequires = [\"maturin&gt;=1.7,&lt;2.0\"]\nbuild-backend = \"maturin\"\n\n[tool.maturin]\nmodule-name = \"rustbpe\"\nbindings = \"pyo3\"\npython-source = \".\"\nmanifest-path = \"rustbpe/Cargo.toml\"\n\n[dependency-groups]\ndev = [\n    \"maturin&gt;=1.9.4\",\n    \"pytest&gt;=8.0.0\",\n]\n\n[tool.pytest.ini_options]\nmarkers = [\n    \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\",\n]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\"]\npython_classes = [\"Test*\"]\npython_functions = [\"test_*\"]\n\n# target torch to cuda 13.0 or CPU\n[tool.uv.sources]\ntorch = [\n    { index = \"pytorch-cpu\", extra = \"cpu\" },\n    { index = \"pytorch-cu130\", extra = \"gpu\" },\n]\n\n[[tool.uv.index]]\nname = \"pytorch-cpu\"\nurl = \"https://download.pytorch.org/whl/cpu\"\nexplicit = true\n\n[[tool.uv.index]]\nname = \"pytorch-cu130\"\nurl = \"https://download.pytorch.org/whl/cu130\"\nexplicit = true\n\n[project.optional-dependencies]\ncpu = [\n    \"torch&gt;=2.9.0\",\n]\ngpu = [\n    \"torch&gt;=2.9.0\",\n]\n\n[tool.uv]\nconflicts = [\n    [\n        { extra = \"cpu\" },\n        { extra = \"gpu\" },\n    ],\n]\n</code></pre>\n<h2><a name=\"p-1700960-install-uv-install-repo-dependencies-activate-venv-3\" class=\"anchor\" href=\"#p-1700960-install-uv-install-repo-dependencies-activate-venv-3\"></a>Install UV, install repo dependencies, activate venv</h2>\n<p>Now you‚Äôre ready to continue following the installation instructions for nanochat as per <a href=\"https://github.com/karpathy/nanochat/discussions/1\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Introducing nanochat: The best ChatGPT that $100 can buy. ¬∑ karpathy/nanochat ¬∑ Discussion #1 ¬∑ GitHub</a> in particular the following steps to install UV, install all repo dependencies, and activate the venv:</p>\n<pre data-code-wrap=\"bash\"><code class=\"lang-bash\"># install uv (if not already installed)\ncommand -v uv &amp;&gt; /dev/null || curl -LsSf https://astral.sh/uv/install.sh | sh\n# create a .venv local virtual environment (if it doesn't exist)\n[ -d \".venv\" ] || uv venv\n# install the repo dependencies\nuv sync\n# activate venv so that `python` uses the project's venv instead of system python\nsource .venv/bin/activate\n</code></pre>\n<h2><a name=\"p-1700960-build-and-train-the-tokenizer-4\" class=\"anchor\" href=\"#p-1700960-build-and-train-the-tokenizer-4\"></a>Build and train the tokenizer</h2>\n<p>You can continue to follow the instructions to build the tokenizer:</p>\n<pre data-code-wrap=\"bash\"><code class=\"lang-bash\"># Install Rust / Cargo\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y\nsource \"$HOME/.cargo/env\"\n# Build the rustbpe Tokenizer\nuv run maturin develop --release --manifest-path rustbpe/Cargo.toml\n</code></pre>\n<p>To download the training dataset:</p>\n<pre data-code-wrap=\"bash\"><code class=\"lang-bash\">python -m nanochat.dataset -n 240\n</code></pre>\n<p>And to train the tokenizer and evaluate it:</p>\n<pre data-code-wrap=\"bash\"><code class=\"lang-bash\">python -m scripts.tok_train --max_chars=2000000000\npython -m scripts.tok_eval\n</code></pre>\n<p>If you haven‚Äôt already done so previously, you also should download the eval bundle at this time:</p>\n<pre data-code-wrap=\"bash\"><code class=\"lang-bash\">curl -L -o eval_bundle.zip https://karpathy-public.s3.us-west-2.amazonaws.com/eval_bundle.zip\nunzip -q eval_bundle.zip\nrm eval_bundle.zip\nmv eval_bundle \"$HOME/.cache/nanochat\"\n</code></pre>\n<h2><a name=\"p-1700960-install-cuda-1302-5\" class=\"anchor\" href=\"#p-1700960-install-cuda-1302-5\"></a>Install CUDA 13.0.2</h2>\n<p>The next step in the nanochat instructions would be to now run pre-training, but that step will fail, because the default <code>ptxas</code> installed with Triton 3.5.0 is the CUDA 12.8 version and doesn‚Äôt know about the <code>sm_121a</code> gpu-name of the Blackwell GB10.</p>\n<p>At this time, you need to go to the nVIDIA Developer website and install CUDA 13.0.2 manually by following the steps here: <a href=\"https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=arm64-sbsa&amp;Compilation=Native&amp;Distribution=Ubuntu&amp;target_version=24.04&amp;target_type=deb_local\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">CUDA Toolkit 13.0 Update 2 Downloads | NVIDIA Developer</a></p>\n<p>In particular, this was the sequence that worked for me on the DGX Spark:</p>\n<pre data-code-wrap=\"bash\"><code class=\"lang-bash\">wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/sbsa/cuda-ubuntu2404.pin\nsudo mv cuda-ubuntu2404.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/13.0.2/local_installers/cuda-repo-ubuntu2404-13-0-local_13.0.2-580.95.05-1_arm64.deb\nsudo dpkg -i cuda-repo-ubuntu2404-13-0-local_13.0.2-580.95.05-1_arm64.deb\nsudo cp /var/cuda-repo-ubuntu2404-13-0-local/cuda-*-keyring.gpg /usr/share/keyrings/\nsudo apt-get update\nsudo apt-get -y install cuda-toolkit-13-0\n</code></pre>\n<p>And now you need to tell Triton to use the new <code>ptxas</code> version you just installed with the CUDA 13.0.2 toolkit:</p>\n<pre data-code-wrap=\"bash\"><code class=\"lang-bash\"># assuming CUDA 13.0 is installed at /usr/local/cuda-13.0\nexport TRITON_PTXAS_PATH=/usr/local/cuda-13.0/bin/ptxas\nexport CUDA_HOME=/usr/local/cuda-13.0\nexport PATH=/usr/local/cuda-13.0/bin:$PATH\nexport LD_LIBRARY_PATH=/usr/local/cuda-13.0/lib64:${LD_LIBRARY_PATH}\n</code></pre>\n<h2><a name=\"p-1700960-run-pre-training-6\" class=\"anchor\" href=\"#p-1700960-run-pre-training-6\"></a>Run pre-training</h2>\n<p>Now you should be able to run pre-training on your GDX Spark with the usual command from the nanochat instructions:</p>\n<pre data-code-wrap=\"bash\"><code class=\"lang-bash\">torchrun --standalone --nproc_per_node=gpu -m scripts.base_train -- --depth=20\n</code></pre>\n<p>That‚Äôs what did the trick for me and here is the result of nanochat running on my DGX Spark:</p>\n<pre><code class=\"lang-auto\">                                                   ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚ñà‚ñà‚ñà‚ñà‚ñà\n                                                  ‚ñë‚ñë‚ñà‚ñà‚ñà                 ‚ñë‚ñë‚ñà‚ñà‚ñà\n ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n‚ñë‚ñë‚ñà‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñë‚ñà‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñë\n ‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñë‚ñë  ‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñë‚ñà‚ñà‚ñà\n ‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà  ‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà‚ñë‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà   ‚ñë‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà\n ‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà\n‚ñë‚ñë‚ñë‚ñë ‚ñë‚ñë‚ñë‚ñë‚ñë  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚ñë‚ñë‚ñë‚ñë ‚ñë‚ñë‚ñë‚ñë‚ñë  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  ‚ñë‚ñë‚ñë‚ñë ‚ñë‚ñë‚ñë‚ñë‚ñë  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    ‚ñë‚ñë‚ñë‚ñë‚ñë\n\nOverriding: depth = 20\nAutodetected device type: cuda\n/home/alf/nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n  _C._set_float32_matmul_precision(precision)\n/home/alf/nanochat/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:283: UserWarning:\n    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n    Minimum and Maximum cuda capability supported by this version of PyTorch is\n    (8.0) - (12.0)\n\n  warnings.warn(\n2025-10-22 21:04:58,661 - nanochat.common - INFO - Distributed world size: 1\nVocab size: 65,536\nnum_layers: 20\nmodel_dim: 1280\nnum_heads: 10\nnum_kv_heads: 10\nTokens / micro-batch / rank: 32 x 2048 = 65,536\nTokens / micro-batch: 65,536\nTotal batch size 524,288 =&gt; gradient accumulation steps: 8\nNumber of parameters: 560,988,160\nEstimated FLOPs per token: 3.491758e+09\nCalculated number of iterations from target data:param ratio: 21,400\nTotal number of training tokens: 11,219,763,200\nTokens : Params ratio: 20.00\nTotal training FLOPs estimate: 3.917670e+19\nScaling the LR for the AdamW parameters ‚àù1/‚àö(1280/768) = 0.774597\nMuon: Grouping 80 params of shape torch.Size([1280, 1280]), device cuda:0, dtype torch.float32\nMuon: Grouping 20 params of shape torch.Size([1280, 5120]), device cuda:0, dtype torch.float32\nMuon: Grouping 20 params of shape torch.Size([5120, 1280]), device cuda:0, dtype torch.float32\nStep 00000 | Validation bpb: 3.3015\nstep 00000/21400 (0.00%) | loss: 11.090355 | lrm: 1.00 | dt: 42376.54ms | tok/sec: 1,546 | mfu: 4.37 | total time: 0.00m\nstep 00001/21400 (0.00%) | loss: 10.817723 | lrm: 1.00 | dt: 39542.98ms | tok/sec: 1,657 | mfu: 4.68 | total time: 0.00m\nstep 00002/21400 (0.01%) | loss: 10.198821 | lrm: 1.00 | dt: 39778.76ms | tok/sec: 1,647 | mfu: 4.65 | total time: 0.00m\nstep 00003/21400 (0.01%) | loss: 9.490393 | lrm: 1.00 | dt: 39976.27ms | tok/sec: 1,639 | mfu: 4.63 | total time: 0.00m\n</code></pre>\n<p>As you can see in the above output, it still shows a brief warning that the GB10 has even more cuda capabilities than what PyTorch currently supports, but the training is now able to correctly run on the DGX Spark.</p>\n<p>Btw, I expect the pre-training to run for a few days, so I actually did all of the above in a <code>screen</code> session to ensure the job wouldn‚Äôt terminate if my ssh connection died for some reason. This will allow me to simply reconnect ssh and then reattach with <code>screen -r jobname</code>.</p>",
        "post_number": 8,
        "post_type": 1,
        "posts_count": 11,
        "updated_at": "2025-10-23T01:18:50.569Z",
        "reply_count": 1,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 99,
        "reads": 57,
        "readers_count": 56,
        "score": 531.2,
        "yours": false,
        "topic_id": 348537,
        "topic_slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
        "display_username": "Alexander Falk",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 2,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://github.com/karpathy/nanochat/discussions/1",
            "internal": false,
            "reflection": false,
            "title": "Introducing nanochat: The best ChatGPT that $100 can buy. ¬∑ karpathy/nanochat ¬∑ Discussion #1 ¬∑ GitHub",
            "clicks": 3
          },
          {
            "url": "https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=arm64-sbsa&Compilation=Native&Distribution=Ubuntu&target_version=24.04&target_type=deb_local",
            "internal": false,
            "reflection": false,
            "title": "CUDA Toolkit 13.0 Update 2 Downloads | NVIDIA Developer",
            "clicks": 3
          }
        ],
        "read": true,
        "user_title": "",
        "bookmarked": false,
        "actions_summary": [
          {
            "id": 2,
            "count": 2
          }
        ],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 4707765,
        "hidden": false,
        "trust_level": 0,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/anyone-got-nanochat-training-working-on-the-dgx-spark/348537/8",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": true,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1700984,
        "name": "Lakamsani",
        "username": "lakamsani",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/lakamsani/{size}/446446_2.png",
        "created_at": "2025-10-23T01:43:16.398Z",
        "cooked": "<p>Thank you for those detailed steps. I had to do an extra step i.e. <code>uv sync --extra gpu</code> before the <code>--nproc_per_node=gpu</code> worked. Now it is running for me as well. This is easier than the docker based approach on tha nanochat repo. <code>tmux</code> ,  <code>tailscale</code> and <code>wandb</code> are working well to monitor the run.</p>\n<p>Sample step:</p>\n<p><code>2025-10-23 03:23:24 step 00104/21400 (0.49%) | loss: 5.183463 | lrm: 1.00 | dt: 42225.72ms | tok/sec: 1,552 | mfu: 4.38 | total time: 65.85m</code></p>\n<p>Thanks to Claude Code. It told me that fix after I gave it this initial error:</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\nFile ‚Äú/home/vamsee/nanochat/.venv/lib/python3.10/site-packages/torch/distributed/run.py‚Äù, line 687, in determine_local_world_size\nreturn int(nproc_per_node)\nValueError: invalid literal for int() with base 10: ‚Äògpu‚Äô\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\nFile ‚Äú/home/vamsee/nanochat/.venv/bin/torchrun‚Äù, line 10, in \nsys.exit(main())\nFile ‚Äú/home/vamsee/nanochat/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/init.py‚Äù, line 357, in wrapper\nreturn f(*args, **kwargs)\nFile ‚Äú/home/vamsee/nanochat/.venv/lib/python3.10/site-packages/torch/distributed/run.py‚Äù, line 936, in main\nrun(args)\nFile ‚Äú/home/vamsee/nanochat/.venv/lib/python3.10/site-packages/torch/distributed/run.py‚Äù, line 926, in run\nconfig, cmd, cmd_args = config_from_args(args)\nFile ‚Äú/home/vamsee/nanochat/.venv/lib/python3.10/site-packages/torch/distributed/run.py‚Äù, line 800, in config_from_args\nnproc_per_node = determine_local_world_size(args.nproc_per_node)\nFile ‚Äú/home/vamsee/nanochat/.venv/lib/python3.10/site-packages/torch/distributed/run.py‚Äù, line 694, in determine_local_world_size\nraise ValueError(‚ÄúCuda is not available.‚Äù) from e\nValueError: Cuda is not available.\n</code></pre>",
        "post_number": 9,
        "post_type": 1,
        "posts_count": 11,
        "updated_at": "2025-10-23T04:56:00.421Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 2,
        "reads": 53,
        "readers_count": 52,
        "score": 35.4,
        "yours": false,
        "topic_id": 348537,
        "topic_slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
        "display_username": "Lakamsani",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 6,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "bookmarked": false,
        "actions_summary": [
          {
            "id": 2,
            "count": 1
          }
        ],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 4700641,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/anyone-got-nanochat-training-working-on-the-dgx-spark/348537/9",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1704826,
        "name": "B K Singh",
        "username": "b_k_singh",
        "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
        "created_at": "2025-10-30T03:50:28.491Z",
        "cooked": "<p>Thank you for the detailed steps. I am able to run it on my dgx spark., now will wait for ~9 days for this to finish. :)</p>\n<p>step 00207/21400 (0.97%) | loss: 4.315866 | lrm: 1.00 | dt: 39788.09ms | tok/sec: 1,647 | mfu: 4.65 | total time: 130.30m<br>\nstep 00208/21400 (0.97%) | loss: 4.303699 | lrm: 1.00 | dt: 39880.74ms | tok/sec: 1,643 | mfu: 4.64 | total time: 130.97m<br>\nstep 00209/21400 (0.98%) | loss: 4.281022 | lrm: 1.00 | dt: 39518.52ms | tok/sec: 1,658 | mfu: 4.68 | total time: 131.63m</p>",
        "post_number": 10,
        "post_type": 1,
        "posts_count": 11,
        "updated_at": "2025-10-30T03:50:28.491Z",
        "reply_count": 1,
        "reply_to_post_number": 8,
        "quote_count": 0,
        "incoming_link_count": 5,
        "reads": 34,
        "readers_count": 33,
        "score": 31.6,
        "yours": false,
        "topic_id": 348537,
        "topic_slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
        "display_username": "B K Singh",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 4707765,
          "username": "afalk42",
          "name": "Alexander Falk",
          "avatar_template": "/user_avatar/forums.developer.nvidia.com/afalk42/{size}/447160_2.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 3402108,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/anyone-got-nanochat-training-working-on-the-dgx-spark/348537/10",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1710696,
        "name": "B K Singh",
        "username": "b_k_singh",
        "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
        "created_at": "2025-11-07T17:40:45.557Z",
        "cooked": "<p>Due to power flicker training got restart but now I see the correct tok/sec:</p>\n<p>Overriding: depth = 20<br>\nOverriding: run = dummy<br>\nAutodetected device type: cuda<br>\n/home/bkprity/GenAI/nanochat/.venv/lib/python3.10/site-packages/torch/<strong>init</strong>.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = ‚Äòtf32‚Äô or torch.backends.cuda.matmul.fp32_precision = ‚Äòieee‚Äô. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see <a href=\"https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">CUDA semantics ‚Äî PyTorch main documentation</a> (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)<br>\n_C._set_float32_matmul_precision(precision)<br>\n/home/bkprity/GenAI/nanochat/.venv/lib/python3.10/site-packages/torch/cuda/<strong>init</strong>.py:283: UserWarning:<br>\nFound GPU0 NVIDIA GB10 which is of cuda capability 12.1.<br>\nMinimum and Maximum cuda capability supported by this version of PyTorch is<br>\n(8.0) - (12.0)</p>\n<p>warnings.warn(<br>\n2025-11-07 11:30:10,639 - nanochat.common - INFO - Distributed world size: 1<br>\nVocab size: 65,536<br>\nnum_layers: 20<br>\nmodel_dim: 1280<br>\nnum_heads: 10<br>\nnum_kv_heads: 10<br>\nTokens / micro-batch / rank: 32 x 2048 = 65,536<br>\nTokens / micro-batch: 65,536<br>\nTotal batch size 524,288 =&gt; gradient accumulation steps: 8<br>\nNumber of parameters: 560,988,160<br>\nEstimated FLOPs per token: 3.491758e+09<br>\nCalculated number of iterations from target data:param ratio: 21,400<br>\nTotal number of training tokens: 11,219,763,200<br>\nTokens : Params ratio: 20.00<br>\nTotal training FLOPs estimate: 3.917670e+19<br>\nScaling the LR for the AdamW parameters ‚àù1/‚àö(1280/768) = 0.774597<br>\nMuon: Grouping 80 params of shape torch.Size([1280, 1280]), device cuda:0, dtype torch.float32<br>\nMuon: Grouping 20 params of shape torch.Size([1280, 5120]), device cuda:0, dtype torch.float32<br>\nMuon: Grouping 20 params of shape torch.Size([5120, 1280]), device cuda:0, dtype torch.float32<br>\n[rank0]:W1107 11:30:13.669000 281160 .venv/lib/python3.10/site-packages/torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode<br>\nStep 00000 | Validation bpb: 3.3015<br>\nstep 00000/21400 (0.00%) | loss: 11.090355 | grad norm: 0.4307 | lrm: 1.00 | dt: 59607.00ms | tok/sec: 8,795 | mfu: 3.11 | total time: 0.00m<br>\nstep 00001/21400 (0.00%) | loss: 10.817723 | grad norm: 11.0388 | lrm: 1.00 | dt: 39792.87ms | tok/sec: 13,175 | mfu: 4.65 | total time: 0.00m<br>\nstep 00002/21400 (0.01%) | loss: 10.198820 | grad norm: 5.7957 | lrm: 1.00 | dt: 39929.17ms | tok/sec: 13,130 | mfu: 4.64 | total time: 0.00m</p>",
        "post_number": 11,
        "post_type": 1,
        "posts_count": 11,
        "updated_at": "2025-11-07T17:40:45.557Z",
        "reply_count": 0,
        "reply_to_post_number": 10,
        "quote_count": 0,
        "incoming_link_count": 4,
        "reads": 17,
        "readers_count": 16,
        "score": 18.2,
        "yours": false,
        "topic_id": 348537,
        "topic_slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
        "display_username": "B K Singh",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "link_counts": [
          {
            "url": "https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices",
            "internal": false,
            "reflection": false,
            "title": "CUDA semantics ‚Äî PyTorch main documentation",
            "clicks": 0
          }
        ],
        "read": true,
        "user_title": null,
        "reply_to_user": {
          "id": 3402108,
          "username": "b_k_singh",
          "name": "B K Singh",
          "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png"
        },
        "bookmarked": false,
        "actions_summary": [],
        "moderator": false,
        "admin": false,
        "staff": false,
        "user_id": 3402108,
        "hidden": false,
        "trust_level": 1,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "post_url": "/t/anyone-got-nanochat-training-working-on-the-dgx-spark/348537/11",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      },
      {
        "id": 1719077,
        "name": "system",
        "username": "system",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/system/{size}/68080_2.png",
        "created_at": "2025-11-21T17:41:15.072Z",
        "cooked": "<p>This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</p>",
        "post_number": 12,
        "post_type": 3,
        "posts_count": 11,
        "updated_at": "2025-11-21T17:41:15.072Z",
        "reply_count": 0,
        "reply_to_post_number": null,
        "quote_count": 0,
        "incoming_link_count": 0,
        "reads": 3,
        "readers_count": 2,
        "score": 0.4,
        "yours": false,
        "topic_id": 348537,
        "topic_slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
        "display_username": "system",
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_bg_color": null,
        "flair_color": null,
        "flair_group_id": null,
        "badges_granted": [],
        "version": 1,
        "can_edit": false,
        "can_delete": false,
        "can_recover": false,
        "can_see_hidden_post": false,
        "can_wiki": false,
        "read": true,
        "user_title": "Moderator",
        "title_is_group": false,
        "bookmarked": false,
        "actions_summary": [],
        "moderator": true,
        "admin": true,
        "staff": true,
        "user_id": -1,
        "hidden": false,
        "trust_level": 4,
        "deleted_at": null,
        "user_deleted": false,
        "edit_reason": null,
        "can_view_edit_history": false,
        "wiki": false,
        "action_code": "autoclosed.enabled",
        "post_url": "/t/anyone-got-nanochat-training-working-on-the-dgx-spark/348537/12",
        "event": null,
        "can_accept_answer": false,
        "can_unaccept_answer": false,
        "accepted_answer": false,
        "topic_accepted_answer": true,
        "can_translate": false
      }
    ],
    "stream": [
      1699678,
      1699700,
      1700862,
      1700885,
      1700898,
      1700936,
      1700960,
      1700984,
      1704826,
      1710696,
      1719077
    ]
  },
  "timeline_lookup": [
    [
      1,
      35
    ],
    [
      3,
      34
    ],
    [
      9,
      27
    ],
    [
      10,
      18
    ],
    [
      11,
      4
    ]
  ],
  "suggested_topics": [],
  "tags": [],
  "tags_descriptions": {},
  "fancy_title": "Anyone got nanochat training working on the DGX spark?",
  "id": 348537,
  "title": "Anyone got nanochat training working on the DGX spark?",
  "posts_count": 11,
  "created_at": "2025-10-21T17:09:06.459Z",
  "views": 658,
  "reply_count": 3,
  "like_count": 5,
  "last_posted_at": "2025-11-21T17:41:15.072Z",
  "visible": true,
  "closed": true,
  "archived": false,
  "has_summary": false,
  "archetype": "regular",
  "slug": "anyone-got-nanochat-training-working-on-the-dgx-spark",
  "category_id": 721,
  "word_count": 3021,
  "deleted_at": null,
  "user_id": 4700641,
  "featured_link": null,
  "pinned_globally": false,
  "pinned_at": null,
  "pinned_until": null,
  "image_url": "https://global.discourse-cdn.com/nvidia/optimized/4X/3/8/f/38f799df0c8634bb41e86b5209160a780f575852_2_1024x512.png",
  "slow_mode_seconds": 0,
  "draft": null,
  "draft_key": "topic_348537",
  "draft_sequence": null,
  "unpinned": null,
  "pinned": false,
  "current_post_number": 1,
  "highest_post_number": 12,
  "deleted_by": null,
  "actions_summary": [
    {
      "id": 4,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 8,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 10,
      "count": 0,
      "hidden": false,
      "can_act": false
    },
    {
      "id": 7,
      "count": 0,
      "hidden": false,
      "can_act": false
    }
  ],
  "chunk_size": 20,
  "bookmarked": false,
  "topic_timer": null,
  "message_bus_last_id": 6,
  "participant_count": 5,
  "show_read_indicator": false,
  "thumbnails": [
    {
      "max_width": null,
      "max_height": null,
      "width": 1200,
      "height": 600,
      "url": "https://global.discourse-cdn.com/nvidia/original/4X/3/8/f/38f799df0c8634bb41e86b5209160a780f575852.png"
    },
    {
      "max_width": 1024,
      "max_height": 1024,
      "width": 1024,
      "height": 512,
      "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/3/8/f/38f799df0c8634bb41e86b5209160a780f575852_2_1024x512.png"
    },
    {
      "max_width": 800,
      "max_height": 800,
      "width": 800,
      "height": 400,
      "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/3/8/f/38f799df0c8634bb41e86b5209160a780f575852_2_800x400.png"
    },
    {
      "max_width": 600,
      "max_height": 600,
      "width": 600,
      "height": 300,
      "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/3/8/f/38f799df0c8634bb41e86b5209160a780f575852_2_600x300.png"
    },
    {
      "max_width": 400,
      "max_height": 400,
      "width": 400,
      "height": 200,
      "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/3/8/f/38f799df0c8634bb41e86b5209160a780f575852_2_400x200.png"
    },
    {
      "max_width": 300,
      "max_height": 300,
      "width": 300,
      "height": 150,
      "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/3/8/f/38f799df0c8634bb41e86b5209160a780f575852_2_300x150.png"
    },
    {
      "max_width": 200,
      "max_height": 200,
      "width": 200,
      "height": 100,
      "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/3/8/f/38f799df0c8634bb41e86b5209160a780f575852_2_200x100.png"
    }
  ],
  "slow_mode_enabled_until": null,
  "related_topics": [
    {
      "fancy_title": "Pretrain nanochat on 2 x DGX Sparks",
      "id": 350564,
      "title": "Pretrain nanochat on 2 x DGX Sparks",
      "slug": "pretrain-nanochat-on-2-x-dgx-sparks",
      "posts_count": 2,
      "reply_count": 0,
      "highest_post_number": 2,
      "image_url": null,
      "created_at": "2025-11-07T10:51:25.011Z",
      "last_posted_at": "2025-11-07T22:55:13.079Z",
      "bumped": true,
      "bumped_at": "2025-11-07T22:55:13.079Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 3,
      "views": 146,
      "category_id": 721,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 4695332,
            "username": "emaadmanzoor",
            "name": "Emaadmanzoor",
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 4594174,
            "username": "simon.thornington",
            "name": "Simon Thornington",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/simon.thornington/{size}/436434_2.png",
            "trust_level": 1
          }
        }
      ]
    },
    {
      "fancy_title": "Pytorch support",
      "id": 71878,
      "title": "Pytorch support",
      "slug": "pytorch-support",
      "posts_count": 32,
      "reply_count": 0,
      "highest_post_number": 32,
      "image_url": null,
      "created_at": "2019-03-22T19:48:03.000Z",
      "last_posted_at": "2021-10-18T17:45:04.788Z",
      "bumped": true,
      "bumped_at": "2019-08-21T02:48:15.000Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 4920,
      "category_id": 76,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 130722,
            "username": "kylezheng04",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/kylezheng04/{size}/16171_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster, Accepted Answer",
          "user": {
            "id": 28444,
            "username": "dusty_nv",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/dusty_nv/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 49726,
            "username": "wangyihuan123",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 211473,
            "username": "moshe.livne",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 6598,
            "username": "nadeemm",
            "name": "",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/nadeemm/{size}/367020_2.png",
            "primary_group_name": "Employee",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "Pre-training Nanochat on DGX Spark (Standalone and Clustered mode)",
      "id": 349604,
      "title": "Pre-training Nanochat on DGX Spark (Standalone and Clustered mode)",
      "slug": "pre-training-nanochat-on-dgx-spark-standalone-and-clustered-mode",
      "posts_count": 1,
      "reply_count": 0,
      "highest_post_number": 1,
      "image_url": "https://global.discourse-cdn.com/nvidia/optimized/4X/1/4/9/149639e3784106ab815370063a3d84fb951dc55d_2_1024x512.png",
      "created_at": "2025-10-30T14:54:35.501Z",
      "last_posted_at": "2025-10-30T14:54:35.876Z",
      "bumped": true,
      "bumped_at": "2025-10-30T14:54:35.876Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": [
        {
          "max_width": null,
          "max_height": null,
          "width": 1200,
          "height": 600,
          "url": "https://global.discourse-cdn.com/nvidia/original/4X/1/4/9/149639e3784106ab815370063a3d84fb951dc55d.png"
        },
        {
          "max_width": 1024,
          "max_height": 1024,
          "width": 1024,
          "height": 512,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/1/4/9/149639e3784106ab815370063a3d84fb951dc55d_2_1024x512.png"
        },
        {
          "max_width": 800,
          "max_height": 800,
          "width": 800,
          "height": 400,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/1/4/9/149639e3784106ab815370063a3d84fb951dc55d_2_800x400.png"
        },
        {
          "max_width": 600,
          "max_height": 600,
          "width": 600,
          "height": 300,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/1/4/9/149639e3784106ab815370063a3d84fb951dc55d_2_600x300.png"
        },
        {
          "max_width": 400,
          "max_height": 400,
          "width": 400,
          "height": 200,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/1/4/9/149639e3784106ab815370063a3d84fb951dc55d_2_400x200.png"
        },
        {
          "max_width": 300,
          "max_height": 300,
          "width": 300,
          "height": 150,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/1/4/9/149639e3784106ab815370063a3d84fb951dc55d_2_300x150.png"
        },
        {
          "max_width": 200,
          "max_height": 200,
          "width": 200,
          "height": 100,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/4X/1/4/9/149639e3784106ab815370063a3d84fb951dc55d_2_200x100.png"
        }
      ],
      "tags": [
        "llm",
        "training",
        "ai-model-training"
      ],
      "tags_descriptions": {},
      "like_count": 1,
      "views": 206,
      "category_id": 723,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": "latest single",
          "description": "Original Poster, Most Recent Poster",
          "user": {
            "id": 4686603,
            "username": "rapha",
            "name": "Rapha",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/rapha/{size}/445064_2.png",
            "trust_level": 1
          }
        }
      ]
    },
    {
      "fancy_title": "Install Pytorch on Jetson TK1",
      "id": 52070,
      "title": "Install Pytorch on Jetson TK1",
      "slug": "install-pytorch-on-jetson-tk1",
      "posts_count": 8,
      "reply_count": 0,
      "highest_post_number": 8,
      "image_url": null,
      "created_at": "2017-07-29T00:55:22.000Z",
      "last_posted_at": "2021-10-18T18:44:41.007Z",
      "bumped": true,
      "bumped_at": "2019-08-12T14:50:03.000Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 2505,
      "category_id": 79,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 42100,
            "username": "LiminMandawa",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster, Accepted Answer",
          "user": {
            "id": 34659,
            "username": "AastaLLL",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/aastalll/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 160067,
            "username": "christina.bukas",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 213769,
            "username": "najam.r.syed",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 194229,
            "username": "TomNVIDIA",
            "name": "TomNVIDIA",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/tomnvidia/{size}/14181_2.png",
            "primary_group_name": "NsightGraphicsPro",
            "flair_name": "Administrator",
            "flair_url": "https://global.discourse-cdn.com/nvidia/original/3X/7/8/786c2b0600281de14dd72c7e2d4b32c9acf7e1de.png",
            "flair_group_id": 56,
            "admin": true,
            "moderator": true,
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "Pytorch with jetpack 4.2 works slowly than 3.3",
      "id": 72901,
      "title": "Pytorch with jetpack 4.2 works slowly than 3.3",
      "slug": "pytorch-with-jetpack-4-2-works-slowly-than-3-3",
      "posts_count": 7,
      "reply_count": 0,
      "highest_post_number": 7,
      "image_url": "https://global.discourse-cdn.com/nvidia/original/3X/1/b/1bb1a9be221499fdb09192c9184ae260b9ce3513.png",
      "created_at": "2019-04-11T14:11:32.000Z",
      "last_posted_at": "2021-10-18T18:32:14.530Z",
      "bumped": true,
      "bumped_at": "2019-04-26T08:17:23.000Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": [
        {
          "max_width": null,
          "max_height": null,
          "width": 920,
          "height": 540,
          "url": "https://global.discourse-cdn.com/nvidia/original/3X/1/b/1bb1a9be221499fdb09192c9184ae260b9ce3513.png"
        },
        {
          "max_width": 800,
          "max_height": 800,
          "width": 800,
          "height": 469,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/3X/1/b/1bb1a9be221499fdb09192c9184ae260b9ce3513_2_800x469.png"
        },
        {
          "max_width": 600,
          "max_height": 600,
          "width": 600,
          "height": 352,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/3X/1/b/1bb1a9be221499fdb09192c9184ae260b9ce3513_2_600x352.png"
        },
        {
          "max_width": 400,
          "max_height": 400,
          "width": 400,
          "height": 234,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/3X/1/b/1bb1a9be221499fdb09192c9184ae260b9ce3513_2_400x234.png"
        },
        {
          "max_width": 300,
          "max_height": 300,
          "width": 300,
          "height": 176,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/3X/1/b/1bb1a9be221499fdb09192c9184ae260b9ce3513_2_300x176.png"
        },
        {
          "max_width": 200,
          "max_height": 200,
          "width": 200,
          "height": 117,
          "url": "https://global.discourse-cdn.com/nvidia/optimized/3X/1/b/1bb1a9be221499fdb09192c9184ae260b9ce3513_2_200x117.png"
        }
      ],
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 1431,
      "category_id": 81,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 202725,
            "username": "tiger_assassin_crazy",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/tiger_assassin_crazy/{size}/11730_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster, Accepted Answer",
          "user": {
            "id": 34659,
            "username": "AastaLLL",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/aastalll/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 6598,
            "username": "nadeemm",
            "name": "",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/nadeemm/{size}/367020_2.png",
            "primary_group_name": "Employee",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "Effective PyTorch and CUDA",
      "id": 348230,
      "title": "Effective PyTorch and CUDA",
      "slug": "effective-pytorch-and-cuda",
      "posts_count": 19,
      "reply_count": 14,
      "highest_post_number": 21,
      "image_url": null,
      "created_at": "2025-10-19T21:38:29.644Z",
      "last_posted_at": "2025-11-18T02:21:45.937Z",
      "bumped": true,
      "bumped_at": "2025-11-18T02:21:45.937Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [
        "cudnn"
      ],
      "tags_descriptions": {},
      "like_count": 6,
      "views": 2588,
      "category_id": 721,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 4630376,
            "username": "markl02us",
            "name": "Markl02us",
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 0
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 43960,
            "username": "abull",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/abull/{size}/382649_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 4417968,
            "username": "naeemgtng",
            "name": "Naeem",
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 4715116,
            "username": "weile.wang",
            "name": "Weile Wang",
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 0
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 4594174,
            "username": "simon.thornington",
            "name": "Simon Thornington",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/simon.thornington/{size}/436434_2.png",
            "trust_level": 1
          }
        }
      ]
    },
    {
      "fancy_title": "TensorFlow wheel for JetPack 4.0 !!",
      "id": 65207,
      "title": "TensorFlow wheel for JetPack 4.0 !!",
      "slug": "tensorflow-wheel-for-jetpack-4-0",
      "posts_count": 17,
      "reply_count": 0,
      "highest_post_number": 17,
      "image_url": null,
      "created_at": "2018-09-18T01:35:24.000Z",
      "last_posted_at": "2018-10-15T02:57:36.000Z",
      "bumped": true,
      "bumped_at": "2018-10-15T02:57:36.000Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 3779,
      "category_id": 75,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": "latest",
          "description": "Original Poster, Most Recent Poster",
          "user": {
            "id": 34659,
            "username": "AastaLLL",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/aastalll/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 78670,
            "username": "rebotnix",
            "name": "Gary Hilgemann",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/rebotnix/{size}/11315_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 39109,
            "username": "AerialRoboticsGuru",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/aerialroboticsguru/{size}/11112_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 73222,
            "username": "erwin.coumans",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/erwin.coumans/{size}/24866_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 35434,
            "username": "Kuonangzhe",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        }
      ]
    },
    {
      "fancy_title": "Digits does not use gpu on Jeton TX2",
      "id": 54049,
      "title": "Digits does not use gpu on Jeton TX2",
      "slug": "digits-does-not-use-gpu-on-jeton-tx2",
      "posts_count": 5,
      "reply_count": 0,
      "highest_post_number": 5,
      "image_url": null,
      "created_at": "2017-10-09T09:51:33.000Z",
      "last_posted_at": "2021-10-18T18:27:08.386Z",
      "bumped": true,
      "bumped_at": "2017-10-09T18:48:53.000Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 931,
      "category_id": 81,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 43227,
            "username": "hamzabekkour92i",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/hamzabekkour92i/{size}/11216_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster, Accepted Answer",
          "user": {
            "id": 28444,
            "username": "dusty_nv",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/dusty_nv/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": 6598,
            "username": "nadeemm",
            "name": "",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/nadeemm/{size}/367020_2.png",
            "primary_group_name": "Employee",
            "trust_level": 2
          }
        }
      ]
    },
    {
      "fancy_title": "Running TLT 3.0 in DGX A100, driver-version error",
      "id": 183558,
      "title": "Running TLT 3.0 in DGX A100, driver-version error",
      "slug": "running-tlt-3-0-in-dgx-a100-driver-version-error",
      "posts_count": 9,
      "reply_count": 5,
      "highest_post_number": 9,
      "image_url": null,
      "created_at": "2021-07-13T21:59:16.016Z",
      "last_posted_at": "2021-09-19T16:27:00.122Z",
      "bumped": true,
      "bumped_at": "2021-07-21T16:26:23.216Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": true,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 0,
      "views": 1437,
      "category_id": 17,
      "featured_link": null,
      "has_accepted_answer": true,
      "posters": [
        {
          "extras": null,
          "description": "Original Poster",
          "user": {
            "id": 49142,
            "username": "leo2105",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/leo2105/{size}/27757_2.png",
            "trust_level": 1
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster, Accepted Answer",
          "user": {
            "id": 75592,
            "username": "ScottEllis",
            "name": "Scott Ellis",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/scottellis/{size}/14043_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": null,
          "description": "Frequent Poster",
          "user": {
            "id": 32408,
            "username": "Morganh",
            "name": null,
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/morganh/{size}/9748_2.png",
            "primary_group_name": "Employee",
            "flair_name": "Employee",
            "flair_group_id": 63,
            "moderator": true,
            "trust_level": 2
          }
        },
        {
          "extras": "latest",
          "description": "Most Recent Poster",
          "user": {
            "id": -1,
            "username": "system",
            "name": "system",
            "avatar_template": "/user_avatar/forums.developer.nvidia.com/system/{size}/68080_2.png",
            "admin": true,
            "moderator": true,
            "trust_level": 4
          }
        }
      ]
    },
    {
      "fancy_title": "ERROR: No supported GPU(s) detected to run this container",
      "id": 84062,
      "title": "ERROR: No supported GPU(s) detected to run this container",
      "slug": "error-no-supported-gpu-s-detected-to-run-this-container",
      "posts_count": 1,
      "reply_count": 0,
      "highest_post_number": 1,
      "image_url": null,
      "created_at": "2019-10-30T11:02:46.000Z",
      "last_posted_at": "2019-10-30T11:02:46.000Z",
      "bumped": false,
      "bumped_at": "2019-10-30T11:02:46.000Z",
      "archetype": "regular",
      "unseen": false,
      "pinned": false,
      "unpinned": null,
      "visible": true,
      "closed": false,
      "archived": false,
      "bookmarked": null,
      "liked": null,
      "thumbnails": null,
      "tags": [],
      "tags_descriptions": {},
      "like_count": 2,
      "views": 2187,
      "category_id": 33,
      "featured_link": null,
      "has_accepted_answer": false,
      "posters": [
        {
          "extras": "latest single",
          "description": "Original Poster, Most Recent Poster",
          "user": {
            "id": 294899,
            "username": "foby",
            "name": null,
            "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
            "trust_level": 1
          }
        }
      ]
    }
  ],
  "summarizable": false,
  "accepted_answer": {
    "post_number": 8,
    "username": "afalk42",
    "name": null,
    "excerpt": "I have managed to get it running on my DGX Spark just now, but it took a couple of hours of trial and error, going through documentation and forums, and consulting with GPT-5 to figure out all the steps necessary‚Ä¶ \nThis is the approach that worked for me: \n<a name=\"p-1700960-clone-repo-and-make-modifications-1\" class=\"anchor\" href=\"#p-1700960-clone-repo-and-make-modifications-1\"></a>Clone repo and make modifications\nGet the r&hellip;",
    "accepter_name": null,
    "accepter_username": "lakamsani"
  },
  "can_vote": false,
  "vote_count": 0,
  "user_voted": false,
  "discourse_zendesk_plugin_zendesk_id": null,
  "discourse_zendesk_plugin_zendesk_url": "https://your-url.zendesk.com/agent/tickets/",
  "details": {
    "can_edit": false,
    "notification_level": 1,
    "participants": [
      {
        "id": 4700641,
        "username": "lakamsani",
        "name": "Lakamsani",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/lakamsani/{size}/446446_2.png",
        "post_count": 5,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 1
      },
      {
        "id": 3402108,
        "username": "b_k_singh",
        "name": "B K Singh",
        "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
        "post_count": 2,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 1
      },
      {
        "id": 4707765,
        "username": "afalk42",
        "name": "Alexander Falk",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/afalk42/{size}/447160_2.png",
        "post_count": 1,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 0
      },
      {
        "id": 65802,
        "username": "dengtianshuo",
        "name": "Tim",
        "avatar_template": "/user_avatar/forums.developer.nvidia.com/dengtianshuo/{size}/447149_2.png",
        "post_count": 1,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 1
      },
      {
        "id": 4707569,
        "username": "michaeljamesott",
        "name": "Michaeljamesott",
        "avatar_template": "https://developer.download.nvidia.com/images/forums/profile-default-devtalk-84.png",
        "post_count": 1,
        "primary_group_name": null,
        "flair_name": null,
        "flair_url": null,
        "flair_color": null,
        "flair_bg_color": null,
        "flair_group_id": null,
        "trust_level": 0
      }
    ],
    "created_by": {
      "id": 4700641,
      "username": "lakamsani",
      "name": "Lakamsani",
      "avatar_template": "/user_avatar/forums.developer.nvidia.com/lakamsani/{size}/446446_2.png"
    },
    "last_poster": {
      "id": -1,
      "username": "system",
      "name": "system",
      "avatar_template": "/user_avatar/forums.developer.nvidia.com/system/{size}/68080_2.png"
    },
    "links": [
      {
        "url": "https://github.com/karpathy/nanochat/discussions/28#discussioncomment-14735913",
        "title": "Anyone managed to run training on an NVIDIA Spark yet? ¬∑ karpathy/nanochat ¬∑ Discussion #28 ¬∑ GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 18,
        "user_id": 65802,
        "domain": "github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://github.com/karpathy/nanochat/blob/master/scripts/base_train.py#L112",
        "title": "nanochat/scripts/base_train.py at master ¬∑ karpathy/nanochat ¬∑ GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 7,
        "user_id": 4700641,
        "domain": "github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://github.com/karpathy/nanochat",
        "title": "GitHub - karpathy/nanochat: The best ChatGPT that $100 can buy.",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 5,
        "user_id": 4700641,
        "domain": "github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=arm64-sbsa&Compilation=Native&Distribution=Ubuntu&target_version=24.04&target_type=deb_local",
        "title": "CUDA Toolkit 13.0 Update 2 Downloads | NVIDIA Developer",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 3,
        "user_id": 4707765,
        "domain": "developer.nvidia.com",
        "root_domain": "nvidia.com"
      },
      {
        "url": "https://github.com/karpathy/nanochat/blob/master/pyproject.toml#L47",
        "title": "nanochat/pyproject.toml at master ¬∑ karpathy/nanochat ¬∑ GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 3,
        "user_id": 4700641,
        "domain": "github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://github.com/karpathy/nanochat/discussions/1",
        "title": "Introducing nanochat: The best ChatGPT that $100 can buy. ¬∑ karpathy/nanochat ¬∑ Discussion #1 ¬∑ GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 3,
        "user_id": 4707765,
        "domain": "github.com",
        "root_domain": "github.com"
      },
      {
        "url": "https://x.com/NVIDIAAIDev/status/1980412464949821570",
        "title": null,
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 1,
        "user_id": 4700641,
        "domain": "x.com",
        "root_domain": "x.com"
      },
      {
        "url": "https://github.com/karpathy/nanochat/blob/master/speedrun.sh#L95",
        "title": "nanochat/speedrun.sh at master ¬∑ karpathy/nanochat ¬∑ GitHub",
        "internal": false,
        "attachment": false,
        "reflection": false,
        "clicks": 1,
        "user_id": 4700641,
        "domain": "github.com",
        "root_domain": "github.com"
      }
    ]
  },
  "bookmarks": []
}